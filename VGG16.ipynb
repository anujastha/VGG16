{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMZLfpMhkWj8MogRI1Yrlem"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"ZvHuwYzndK30"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## importing libraries\n"],"metadata":{"id":"q2H4iukeddQB"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","from tqdm import tqdm # for progress bar\n","\n","# Libraries for TensorFlow\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras import models, layers\n","from tensorflow import keras\n","\n","# Library for Transfer Learning\n","from tensorflow.keras.applications import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","\n","print(\"Importing libraries completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6IxBjocdd44","executionInfo":{"status":"ok","timestamp":1696956363190,"user_tz":-345,"elapsed":6196,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"751cd52d-09cd-4223-be23-e5970b30cc52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Importing libraries completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4tgjx63Bdocr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#. Data Gethering"],"metadata":{"id":"ByHvdK6idsEp"}},{"cell_type":"code","source":["# Loading dataset from keras\n","\n","(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()"],"metadata":{"id":"lxR0uShHdsmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verifying dataset\n","\n","print(xtrain.shape)\n","print(ytrain.shape)\n","print(xtest.shape)\n","print(ytest.shape)\n","print(ytrain)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XXpdCp6du42","executionInfo":{"status":"ok","timestamp":1696956363191,"user_tz":-345,"elapsed":24,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"7bd12716-697b-4981-88dd-8c76ca2b79a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28)\n","(60000,)\n","(10000, 28, 28)\n","(10000,)\n","[5 0 4 ... 5 6 8]\n"]}]},{"cell_type":"code","source":["#2.1 Processing data to make it compitable with VGG16"],"metadata":{"id":"F2bP1NfmdxhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Rpxi0O3Xd1zf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2.1 Processing data to make it compitable with VGG16"],"metadata":{"id":"BSeFKz-9d3Re"}},{"cell_type":"code","source":["# Convert the images into 3 channels as MNIST images are Black and White so have 1 channel\n","\n","xtrain=np.dstack([xtrain] * 3)\n","xtest=np.dstack([xtest]*3)\n","xtrain.shape,xtest.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xy4nLBc5d3tz","executionInfo":{"status":"ok","timestamp":1696956363909,"user_tz":-345,"elapsed":736,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"c5facada-1b60-4f8d-823c-3441e0e6e3da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 84), (10000, 28, 84))"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Reshape images as per the tensor format required by tensorflow\n","\n","xtrain = xtrain.reshape(-1, 28,28,3)\n","xtest= xtest.reshape (-1,28,28,3)\n","xtrain.shape,xtest.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxL7kaI-d6gY","executionInfo":{"status":"ok","timestamp":1696956363910,"user_tz":-345,"elapsed":6,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"3b34dbec-95e5-4d24-85a3-e0698e47c057"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28, 3), (10000, 28, 28, 3))"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Resize the images 48*48 as required by VGG16\n","\n","from keras.preprocessing.image import img_to_array, array_to_img\n","\n","xtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\n","xtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n","#train_x = preprocess_input(x)\n","xtrain.shape, xtest.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q3Vm6ssYd9cw","executionInfo":{"status":"ok","timestamp":1696956373438,"user_tz":-345,"elapsed":9532,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"cb35ef5a-7a5f-46dd-e36e-94fa8d4e6ace"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 48, 48, 3), (10000, 48, 48, 3))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# # listing the folders containing images\n","\n","# preparing array that can be used later\n","\n","class_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","print(class_names)\n","\n","val_class_names =['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","print(val_class_names)\n","\n","test_class_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","print(test_class_names)\n","\n","# Function to know the name of the element\n","\n","def Get_Element_Name(argument):\n","    switcher = {\n","        0: \"Zero\",\n","        1: \"One\",\n","        2: \"Two\",\n","        3: \"Three\",\n","        4: \"Four\",\n","        5: \"Five\",\n","        6: \"Six\",\n","        7: \"Seven\",\n","        8: \"Eight\",\n","        9: \"Nine\",\n","    }\n","    return switcher.get(argument, \"Invalid\")\n","\n","print(Get_Element_Name(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hH0PU1bZd_Tf","executionInfo":{"status":"ok","timestamp":1696956373439,"user_tz":-345,"elapsed":33,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"c76c1ef2-0185-41d5-9a56-f3aab8dc9d26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n","Zero\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rP9G6203eI8c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preparing Data"],"metadata":{"id":"k7hfMQ0DeM-2"}},{"cell_type":"code","source":["\n","x=[] # to store array value of the images\n","x=xtrain\n","y=[] # to store the labels of the images\n","y=ytrain\n","\n","test_images=[]\n","test_images=xtest\n","test_images_Original=[]\n","test_images_Original=xtest\n","test_image_label=[] # to store the labels of the images\n","test_image_label=ytest\n","\n","val_images=[]\n","val_images=xtest\n","val_images_Original=[]\n","val_images_Original=xtest\n","val_image_label=[] # to store the labels of the images\n","val_image_label=ytest # to store the labels of the images\n","\n","print(\"Preparing Dataset Completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6gA_hw-eNcb","executionInfo":{"status":"ok","timestamp":1696956373440,"user_tz":-345,"elapsed":15,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"c8512d30-cfa8-4ef0-d805-40ff96e4e194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing Dataset Completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"iRfBoJNFeP6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Verification of Data"],"metadata":{"id":"JPZx-XY-eR7V"}},{"cell_type":"code","source":["\n","# Training Dataset\n","print(\"Training Dataset\")\n","\n","x=np.array(x) # Converting to np arrary to pass to the model\n","print(x.shape)\n","\n","y=to_categorical(y) # onehot encoding of the labels\n","# print(y)\n","print(y.shape)\n","\n","# Test Dataset\n","print(\"Test Dataset\")\n","\n","test_images=np.array(test_images)\n","print(test_images.shape)\n","\n","test_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\n","print(test_image_label.shape)\n","\n","# Validation Dataset\n","print(\"Validation Dataset\")\n","val_images=np.array(val_images)\n","print(val_images.shape)\n","\n","val_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\n","print(val_image_label.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdRnVp16eShF","executionInfo":{"status":"ok","timestamp":1696956374236,"user_tz":-345,"elapsed":809,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"8c4b95e8-f063-47ae-8092-78cfbe6df52c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Dataset\n","(60000, 48, 48, 3)\n","(60000, 10)\n","Test Dataset\n","(10000, 48, 48, 3)\n","(10000, 10)\n","Validation Dataset\n","(10000, 48, 48, 3)\n","(10000, 10)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GcC4bs1peYae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#"],"metadata":{"id":"tYVKoFBXedSN"}},{"cell_type":"markdown","source":["#Building a Model: Using Transfer Learning"],"metadata":{"id":"kcnPHDyLel9S"}},{"cell_type":"code","source":["# Check properties of the model that we are going to use for Transfer Learning\n","\n","print(\"Summary of default VGG16 model.\\n\")\n","\n","# we are using VGG16 for transfer learnin here. So we have imported it\n","from tensorflow.keras.applications import VGG16\n","\n","# initializing model with weights='imagenet'i.e. we are carring its original weights\n","model_vgg16=VGG16(weights='imagenet')\n","\n","# display the summary to see the properties of the model\n","model_vgg16.summary()"],"metadata":{"id":"3fvJKUSFemrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (224,224,3)\n","input_layer=layers.Input(shape=(48,48,3))\n","\n","# initialize the transfer model VGG16 with appropriate properties per our need.\n","# we are passing paramers as following\n","# 1) weights='imagenet' - Using this we are carring weights as of original weights.\n","# 2) input_tensor to pass the VGG16 using input_tensor\n","# 3) we want to change the last layer so we are not including top layer\n","model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n","\n","# See the summary of the model with our properties.\n","model_vgg16.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wroq0w0Ge7rW","executionInfo":{"status":"ok","timestamp":1696956422643,"user_tz":-345,"elapsed":4597,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"9a6be86c-987d-432d-f3d0-73e0335e7371"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Custom VGG16 model.\n","\n","1) We setup input layer and 2) We removed top (last) layer. \n","\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14714688 (56.13 MB)\n","Trainable params: 14714688 (56.13 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Observation:\n","\n","The first layer is having image size = (224,224,3) now as we defined.\n","Also, see the folloiwng 2 top (last) layers which were there in original VGG16 are now not the part of our customized layer because we set include_top=False:\n","block5_pool (MaxPooling2D) (None, 7, 7, 512) 0\n","\n","flatten (Flatten) (None, 25088) 0\n","\n","fc1 (Dense) (None, 4096) 102764544\n","\n","fc2 (Dense) (None, 4096) 16781312\n","\n","predictions (Dense) (None, 1000) 4097000"],"metadata":{"id":"jL9tyCFUfHEZ"}},{"cell_type":"code","source":["# access the current last layer of the model and add flatten and dense after it\n","\n","print(\"Summary of Custom VGG16 model.\\n\")\n","print(\"1) We flatten the last layer and added 1 Dense layer and 1 output layer.\\n\")\n","\n","last_layer=model_vgg16.output # we are taking last layer of the model\n","\n","# Add flatten layer: we are extending Neural Network by adding flattn layer\n","flatten=layers.Flatten()(last_layer)\n","\n","# Add dense layer\n","dense1=layers.Dense(100,activation='relu')(flatten)\n","dense1=layers.Dense(100,activation='relu')(flatten)\n","dense1=layers.Dense(100,activation='relu')(flatten)\n","\n","# Add dense layer to the final output layer\n","output_layer=layers.Dense(10,activation='softmax')(flatten)\n","\n","# Creating modle with input and output layer\n","model=models.Model(inputs=input_layer,outputs=output_layer)\n","\n","# Summarize the model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cz_IFv1HfI2e","executionInfo":{"status":"ok","timestamp":1696956480554,"user_tz":-345,"elapsed":1062,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"23934fae-ac57-4c1d-fff3-8c7d6ef8573d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of Custom VGG16 model.\n","\n","1) We flatten the last layer and added 1 Dense layer and 1 output layer.\n","\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 14719818 (56.15 MB)\n","Trainable params: 14719818 (56.15 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# we will freez all the layers except the last layer\n","\n","# we are making all the layers intrainable except the last layer\n","print(\"We are making all the layers intrainable except the last layer. \\n\")\n","for layer in model.layers[:-1]:\n","    layer.trainable=False\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRk7xyAufPNW","executionInfo":{"status":"ok","timestamp":1696956492120,"user_tz":-345,"elapsed":547,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"131eb342-7e91-4074-f6d0-27c3d6c5da32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We are making all the layers intrainable except the last layer. \n","\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 14719818 (56.15 MB)\n","Trainable params: 5130 (20.04 KB)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Train the Model\n","\n","from sklearn.model_selection import train_test_split\n","xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)\n","# print(xtrain)\n","# print(xtest)\n","# print(ytrain)\n","# print(ytest)\n","\n","print(\"Splitting data for train and test completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6JMhPVwfSQ8","executionInfo":{"status":"ok","timestamp":1696956505669,"user_tz":-345,"elapsed":2000,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"df556bb3-0eb3-4490-9483-08cc8474a128"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Splitting data for train and test completed.\n"]}]},{"cell_type":"code","source":["# Compiling Model\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n","\n","print(\"Model compilation completed.\")\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-FWFQ87fVC2","executionInfo":{"status":"ok","timestamp":1696956521189,"user_tz":-345,"elapsed":641,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"3f9a4341-bbe3-40e5-9fcc-d4d0b3c44491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model compilation completed.\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 14719818 (56.15 MB)\n","Trainable params: 5130 (20.04 KB)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Fit the Model\n","\n","# xtrain2=xtrain.reshape(60000,48,48,3)\n","# xtest2=xtest.reshape(10000,48,48,3)\n","\n","history = model.fit(xtrain,ytrain,epochs=20,batch_size=128,verbose=True,validation_data=(xtest,ytest))\n","\n","print(\"Fitting the model completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRyMiWRyfZYG","executionInfo":{"status":"ok","timestamp":1696956919889,"user_tz":-345,"elapsed":385793,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}},"outputId":"53553a69-e4ee-4f0e-acab-214b9c76e471"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","375/375 [==============================] - 28s 48ms/step - loss: 2.1746 - accuracy: 0.7129 - val_loss: 0.6845 - val_accuracy: 0.8470\n","Epoch 2/20\n","375/375 [==============================] - 14s 38ms/step - loss: 0.5047 - accuracy: 0.8761 - val_loss: 0.4342 - val_accuracy: 0.8877\n","Epoch 3/20\n","375/375 [==============================] - 14s 39ms/step - loss: 0.3584 - accuracy: 0.9005 - val_loss: 0.3406 - val_accuracy: 0.9061\n","Epoch 4/20\n","375/375 [==============================] - 16s 44ms/step - loss: 0.2993 - accuracy: 0.9132 - val_loss: 0.3130 - val_accuracy: 0.9111\n","Epoch 5/20\n","375/375 [==============================] - 15s 41ms/step - loss: 0.2702 - accuracy: 0.9194 - val_loss: 0.2844 - val_accuracy: 0.9174\n","Epoch 6/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2517 - accuracy: 0.9227 - val_loss: 0.2789 - val_accuracy: 0.9199\n","Epoch 7/20\n","375/375 [==============================] - 17s 46ms/step - loss: 0.2423 - accuracy: 0.9244 - val_loss: 0.2622 - val_accuracy: 0.9196\n","Epoch 8/20\n","375/375 [==============================] - 14s 38ms/step - loss: 0.2403 - accuracy: 0.9256 - val_loss: 0.2761 - val_accuracy: 0.9194\n","Epoch 9/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2341 - accuracy: 0.9263 - val_loss: 0.2573 - val_accuracy: 0.9247\n","Epoch 10/20\n","375/375 [==============================] - 14s 38ms/step - loss: 0.2289 - accuracy: 0.9276 - val_loss: 0.2655 - val_accuracy: 0.9202\n","Epoch 11/20\n","375/375 [==============================] - 17s 45ms/step - loss: 0.2327 - accuracy: 0.9272 - val_loss: 0.2573 - val_accuracy: 0.9221\n","Epoch 12/20\n","375/375 [==============================] - 17s 45ms/step - loss: 0.2246 - accuracy: 0.9298 - val_loss: 0.2608 - val_accuracy: 0.9218\n","Epoch 13/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2261 - accuracy: 0.9294 - val_loss: 0.2665 - val_accuracy: 0.9197\n","Epoch 14/20\n","375/375 [==============================] - 17s 45ms/step - loss: 0.2304 - accuracy: 0.9276 - val_loss: 0.2805 - val_accuracy: 0.9200\n","Epoch 15/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2259 - accuracy: 0.9284 - val_loss: 0.2966 - val_accuracy: 0.9145\n","Epoch 16/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2237 - accuracy: 0.9302 - val_loss: 0.2666 - val_accuracy: 0.9218\n","Epoch 17/20\n","375/375 [==============================] - 14s 38ms/step - loss: 0.2233 - accuracy: 0.9284 - val_loss: 0.2704 - val_accuracy: 0.9229\n","Epoch 18/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2247 - accuracy: 0.9298 - val_loss: 0.2718 - val_accuracy: 0.9203\n","Epoch 19/20\n","375/375 [==============================] - 17s 44ms/step - loss: 0.2218 - accuracy: 0.9294 - val_loss: 0.2775 - val_accuracy: 0.9187\n","Epoch 20/20\n","375/375 [==============================] - 14s 38ms/step - loss: 0.2194 - accuracy: 0.9305 - val_loss: 0.2830 - val_accuracy: 0.9190\n","Fitting the model completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OBs7HQj8fcee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model Evaluation"],"metadata":{"id":"28tJwNWYffn1"}},{"cell_type":"code","source":["# This function helps to predict individual image supplied to it\n","\n","# Function 1\n","\n","def predict(img_name):\n","    img=image.load_img(img_name,target_size=(48,48))\n","    img=image.img_to_array(img)\n","    plt.imshow(img.astype('int32'))\n","    plt.show()\n","    img=preprocess_input(img)\n","\n","    prediction=model.predict(img.reshape(1,48,48,3))\n","    output=np.argmax(prediction)\n","\n","    print(class_names[output] + \": \" + Get_Element_Name(class_names[output]))\n","\n","    # Function 2\n","\n","# This function plots the image supplied in array\n","def plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n","\n","    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    plt.imshow(img.astype('int32'))\n","\n","    predicted_label=np.argmax(predictions_array)\n","    true_label=np.argmax(true_label)\n","\n","    if predicted_label == true_label: #setting up label color\n","        color='green' # correct then blue colour\n","    else:\n","        color='red' # wrong then red colour\n","        lt.xlabel(\"{} {:2.0f}% \\n ({})\".format(Get_Element_Name(predicted_label),\n","                                            100*np.max(predictions_array), Get_Element_Name(true_label),\n","                                            color=color, horizontalalignment='left'))\n","\n","\n","#     plt.xlabel(\"{} {:2.0f}% ({})\".format(val_class_names[predicted_label],\n","#                                          100*np.max(predictions_array), val_class_names[true_label]),\n","#                                          color=color)\n","\n","\n","# Function 3\n","\n","# This function plots bar chart supplied in the array data\n","def plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n","    predictions_array, true_label = predictions_array[i], true_label[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    predicted_label=np.argmax(predictions_array)\n","    true_label=np.argmax(true_label)\n","\n","    if predicted_label == 0:\n","        predicted_label=1\n","    if true_label == 0:\n","        true_label=1\n","\n","    thisplot=plt.bar(range(10), predicted_label, color='seashell')\n","    plt.ylim([0,1])\n","\n","    thisplot[predicted_label].set_color('red')\n","    thisplot[true_label].set_color('green')"],"metadata":{"id":"T4tK3QMhfgRQ","executionInfo":{"status":"ok","timestamp":1697174664153,"user_tz":-345,"elapsed":783,"user":{"displayName":"Anuja Shrestha","userId":"09239337847647552291"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ew6MRpeXfqSr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predictions"],"metadata":{"id":"5XgxRrb2fuGf"}},{"cell_type":"code","source":["# Preparing prediction arrary\n","predictions=[]\n","\n","for img in tqdm(val_images):\n","    img=img.reshape(1,48,48,3)\n","    predictions.append(model.predict(img))"],"metadata":{"id":"BuvRq0ZFfuqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Declaring variables\n","num_rows=5\n","num_cols=5\n","num_images=num_rows*num_cols\n","\n","plt.figure(figsize=(2*2*num_cols,2*num_rows))\n","\n","print(\"Classification of using Transfer Learning (VGG16)\\n\")\n","print(\"Predicted, Percentage, (Original)\\n\")\n","\n","for i in range(num_images):\n","    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","    ii=random.randrange(1,10000)\n","    # we are passing \"val_images_Original\" just to show original image instead of \"val_images\"\n","    # which is preprocessed as VGG16 process and used for prediction.\n","    plot_image(ii,predictions, val_image_label, val_images_Original)\n","\n","    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","\n","    plot_value_array(i, predictions, val_image_label)\n","plt.subplots_adjust(hspace=0.5)\n","plt.show()"],"metadata":{"id":"kzKtjXTkfw98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the loss and accuracy\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","\n","plt.title('Training and validation accuracy')\n","plt.plot(epochs, acc, 'red', label='Training acc')\n","plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n","plt.legend()\n","\n","plt.figure()\n","plt.title('Training and validation loss')\n","plt.plot(epochs, loss, 'red', label='Training loss')\n","plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n","\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"f2An2t7Uf6dq"},"execution_count":null,"outputs":[]}]}